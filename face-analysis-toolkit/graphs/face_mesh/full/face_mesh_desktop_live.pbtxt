# MediaPipe Facemesh solution extension that support face aligment, blink detection
# Full with annotated video output

# Input image. (ImageFrame)
input_stream: "input_video"

# Output image with rendered results. (ImageFrame)
output_stream: "output_video"

# Proctor Results (std::vector<ProctorResult>)
output_stream: "multi_face_proctor_results"

# Throttles the images flowing downstream for flow control. It passes through
# the very first incoming image unaltered, and waits for downstream nodes
# (calculators and subgraphs) in the graph to finish their tasks before it
# passes through another image. All images that come in while waiting are
# dropped, limiting the number of in-flight images in most part of the graph to
# 1. This prevents the downstream nodes from queuing up incoming images and data
# excessively, which leads to increased latency and memory usage, unwanted in
# real-time mobile applications. It also eliminates unnecessarily computation,
# e.g., the output produced by a node may get dropped downstream if the
# subsequent nodes are still busy processing previous inputs.
node {
  calculator: "FlowLimiterCalculator"
  input_stream: "input_video"
  input_stream: "FINISHED:output_video"
  input_stream_info: {
    tag_index: "FINISHED"
    back_edge: true
  }
  output_stream: "throttled_input_video"
}

# Defines side packets for further use in the graph.
node {
  calculator: "ConstantSidePacketCalculator"
  output_side_packet: "PACKET:0:num_faces"
  output_side_packet: "PACKET:1:with_attention"
  node_options: {
    [type.googleapis.com/mediapipe.ConstantSidePacketCalculatorOptions]: {
      packet { int_value: 1 }
      packet { bool_value: true }
    }
  }
}

# Subgraph that detects faces and corresponding landmarks.
node {
  calculator: "FaceLandmarkFrontCpu"
  input_stream: "IMAGE:throttled_input_video"
  input_side_packet: "NUM_FACES:num_faces"
  input_side_packet: "WITH_ATTENTION:with_attention"
  output_stream: "LANDMARKS:multi_face_landmarks"
  output_stream: "ROIS_FROM_LANDMARKS:face_rects_from_landmarks"
  output_stream: "DETECTIONS:face_detections"
  output_stream: "ROIS_FROM_DETECTIONS:face_rects_from_detections"
}

# Outputs each element of multi_face_landmarks at a fake timestamp for the rest
# of the graph to process. At the end of the loop, outputs the BATCH_END
# timestamp for downstream calculators to inform them that all elements in the
# vector have been processed.
node {
  calculator: "BeginLoopNormalizedLandmarkListVectorCalculator"
  input_stream: "ITERABLE:multi_face_landmarks"
  output_stream: "ITEM:face_landmarks"
  output_stream: "BATCH_END:landmark_timestamp"
}

  # Standardize the landmarks
  node {
    calculator: "LandmarkStandardizationCalculator"
    input_stream: "face_landmarks"
    output_stream: "face_std_landmarks"
  }

  # Detect face movements
  node {
    calculator: "FaceMovementCalculator"
    input_stream: "face_landmarks"
    output_stream: "face_movement"
  }

  # Detect facial activity
  node {
    calculator: "FaceActivityCalculator"
    input_stream: "face_std_landmarks"
    output_stream: "face_activity"
  }

  # Detect orientations
  node {
    calculator: "FaceOrientationCalculator"
    input_stream: "face_std_landmarks"
    output_stream: "face_orientations"
  }

  # Detect Eye blink
  node {
    calculator: "EyeBlinkCalculator"
    input_stream: "face_std_landmarks"
    output_stream: "face_blinks"
  }

  node  {
    calculator: "ProctorResultCalculator"
    input_stream: "ORIENT:face_orientations"
    input_stream: "BLINK:face_blinks"
    input_stream: "ACTIVE:face_activity"
    input_stream: "MOVE:face_movement"
    output_stream: "RESULT:face_proctor_result"
  }

# Collects a ProctorResult object for each hand into a vector. Upon receiving the
# BATCH_END timestamp, outputs the vector of ProctorResult at the BATCH_END
# timestamp.
node {
  calculator: "EndLoopProctorResultVectorCalculator"
  input_stream: "ITEM:face_proctor_result"
  input_stream: "BATCH_END:landmark_timestamp"
  output_stream: "ITERABLE:multi_face_proctor_results"
}

# Subgraph that renders face-landmark annotation onto the input image.
node {
  calculator: "FaceRendererCpu"
  input_stream: "IMAGE:throttled_input_video"
  input_stream: "NORM_RECTS:face_rects_from_landmarks"
  input_stream: "RESULT:multi_face_proctor_results"
  output_stream: "IMAGE:output_video"
}
